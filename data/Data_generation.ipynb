{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "colab": {
   "name": "Data generation",
   "provenance": [],
   "collapsed_sections": []
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MziohhXCNTvd"
   },
   "source": [
    "# Generation of spiking data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTDmen9u6yOl"
   },
   "source": [
    "### Library import and drive setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8qHQxvelNTvn"
   },
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "random.seed(123)\n",
    "np.random.seed(123)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "__eeA8OjEGYN"
   },
   "source": [
    "def save_obj(obj, path):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-5iC4qUpCD-"
   },
   "source": [
    "### Import data and transform it to right format"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eXKZVQd4iW_m"
   },
   "source": [
    "from DatasetBuilding import *"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZRDCXcx3KjEC"
   },
   "source": [
    "labels = ['Sleeping', 'Toileting', 'Showering', 'Breakfast', 'Grooming',\n",
    "          'Spare_Time/TV', 'Leaving', 'Lunch', 'Snack', 'Dinner']\n",
    "def set_class_from_label(label):\n",
    "  if label in labels:\n",
    "    return labels.index(label)\n",
    "  else:\n",
    "    return 10 #other class"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2TuMzgHEpIJ6"
   },
   "source": [
    "# Read the pre-processed data\n",
    "df_A = pd.read_csv('OrdonezA.csv')\n",
    "df_B = pd.read_csv('OrdonezB.csv')\n",
    "\n",
    "# add bias\n",
    "df_A.insert(0, 'Bias', 1)\n",
    "df_B.insert(0, 'Bias', 1)\n",
    "\n",
    "df_A['Class'] = df_A['Label'].apply(lambda x: set_class_from_label(x))\n",
    "df_B['Class'] = df_B['Label'].apply(lambda x: set_class_from_label(x))\n",
    "\n",
    "df_A['t'] = df_A.index\n",
    "df_B['t'] = df_B.index"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Split into train, val, test (60-20-20)\n",
    "df_A['set'] = df_A['t'].apply(lambda x: train_test_split(x, df_A))\n",
    "df_B['set'] = df_B['t'].apply(lambda x: train_test_split(x, df_B))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "P6yaFIm0_hJV"
   },
   "source": [
    "df_data = pd.concat([df_A, df_B])\n",
    "df_data['Label'] = df_data['Label'].apply(lambda x: 'Other' if pd.isna(x) else x)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-vF0-Dh6dSGq"
   },
   "source": [
    "# Generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WU0Bporb3qkJ"
   },
   "source": [
    "# First, write a dataset with samples of 900 seconds for tuning and training\n",
    "duration = 900\n",
    "\n",
    "X_train_A, y_train_A = generate_dataset(df_A[df_A['set']=='train'], duration)\n",
    "X_val_A, y_val_A = generate_dataset(df_A[df_A['set']=='val'], duration)\n",
    "X_test_A, y_test_A = generate_dataset(df_A[df_A['set']=='test'], duration)\n",
    "X_train_B, y_train_B = generate_dataset(df_B[df_B['set']=='train'], duration)\n",
    "X_val_B, y_val_B = generate_dataset(df_B[df_B['set']=='val'], duration)\n",
    "X_test_B, y_test_B = generate_dataset(df_B[df_B['set']=='test'], duration)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# X_train = {'times': np.append(X_train_A['times'], X_train_B['times']),\n",
    "#            'units': np.append(X_train_A['units'], X_train_B['units'])}\n",
    "# X_val = {'times': np.append(X_val_A['times'], X_val_B['times']),\n",
    "#            'units': np.append(X_val_A['units'], X_val_B['units'])}\n",
    "# X_test = {'times': np.append(X_test_A['times'], X_test_B['times']),\n",
    "#            'units': np.append(X_test_A['units'], X_test_B['units'])}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# dataset = {'X_train': X_train,\n",
    "#            'y_train': np.append(y_train_A, y_train_B, axis=0),\n",
    "#            'X_val': X_val,\n",
    "#            'y_val': np.append(y_val_A, y_val_B, axis = 0),\n",
    "#            'X_test': X_test,\n",
    "#            'y_test': np.append(y_test_A, y_test_B, axis=0)}\n",
    "\n",
    "# save_obj(dataset, 'dataset900.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ITXHt2hwPRhJ"
   },
   "source": [
    "# Secondly, generate a dataset for the explanation experiments that takes the whole sequence into account\n",
    "\n",
    "X_train_A, y_train_A = generate_dataset(df_A[df_A['set']=='train'], len(df_A[df_A['set']=='train']))\n",
    "X_val_A, y_val_A = generate_dataset(df_A[df_A['set']=='val'], len(df_A[df_A['set']=='val']))\n",
    "X_test_A, y_test_A = generate_dataset(df_A[df_A['set']=='test'], len(df_A[df_A['set']=='test']))\n",
    "X_train_B, y_train_B = generate_dataset(df_B[df_B['set']=='train'], len(df_B[df_B['set']=='train']))\n",
    "X_val_B, y_val_B = generate_dataset(df_B[df_B['set']=='val'], len(df_B[df_B['set']=='val']))\n",
    "X_test_B, y_test_B = generate_dataset(df_B[df_B['set']=='test'], len(df_B[df_B['set']=='test']))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "alVDw2rOD1Gw"
   },
   "source": [
    "dataset_max = {'X_train_A': X_train_A,\n",
    "               'y_train_A': y_train_A,\n",
    "               'X_train_B': X_train_B,\n",
    "               'y_train_B': y_train_B,\n",
    "               'X_val_A': X_val_A,\n",
    "               'y_val_A': y_val_A,\n",
    "               'X_val_B': X_val_B,\n",
    "               'y_val_B': y_val_B,\n",
    "               'X_test_A': X_test_A,\n",
    "               'y_test_A': y_test_A,\n",
    "               'X_test_B': X_test_B,\n",
    "               'y_test_B': y_test_B}\n",
    "\n",
    "save_obj(dataset_max, 'dataset_max.pkl')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "t3W98JHFbxl_"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}