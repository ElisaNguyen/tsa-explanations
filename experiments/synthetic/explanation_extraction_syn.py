# -*- coding: utf-8 -*-
"""QuantitativeEvaluation - Playground.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kEoqH20gWonAYJ1YBCgkdKuYRq96FUW3

# Import libraries, models, data
"""

import os
import random
import sys
import numpy as np
import pandas as pd
from sklearn import metrics
import torch
import matplotlib.pyplot as plt
from tqdm import tqdm


random.seed(123)
torch.manual_seed(123)
np.random.seed(123)


dtype = torch.float

# Check whether a GPU is available
if torch.cuda.is_available():
    device = torch.device("cuda")     
else:
    device = torch.device("cpu")

print(device)


sys.path.insert(1, '/local/work/enguyen')
from CoreSNN import *
from ExplanationCreationGeneral import *
from ExplanationEvaluationNEW import *

# Load data
syn_data = load_obj('/local/work/enguyen/data/syn_data.pkl')

testset_expl = load_obj('/local/work/enguyen/data/expl_syn_testset.pkl')

y_true = syn_data['y_test'][:, testset_expl]

# Fixed parameters, nbsteps and max time correspond to the set duration (for testing, first we consider the validation set and not the test set)
nb_inputs  = 3
nb_outputs = 4

def initiate_model(nb_layers, t):
    """
    Function that initiates a SNN model with nb_layers which runs data of duration t, only defined for 3 layers
    :param nb_layers: (int) to define the number of layers
    :param t: max_time and nb_steps is defined by this (int)
    """
    nb_inputs = 3
    nb_outputs = 4
    if nb_layers == 1:
        params_onelayer = {'time_step': 0.001,
               'tau_syn': 0.01,
               'tau_mem': 0.001,
               'optimizer': optim.Adam,
               'learning_rate': 0.01,
               'batch_size': 128}
        model = SNN(hyperparams=params_onelayer, 
                          nb_inputs=nb_inputs, 
                          nb_outputs=nb_outputs, 
                          nb_layers=1, 
                          nb_steps=t, 
                          max_time=t)

        model.inference('/local/work/enguyen/synthetic/one_weights.pt')
        return model
    elif nb_layers == 2:
        params_twolayer = {'time_step': 0.001,
               'tau_syn': 0.01,
               'tau_mem': 0.001,
               'optimizer': optim.Adam,
               'learning_rate': 0.01,
               'batch_size': 128,
               'nb_hiddens': [10]}
        model = SNN(hyperparams=params_twolayer, 
                          nb_inputs=nb_inputs, 
                          nb_outputs=nb_outputs, 
                          nb_layers=2, 
                          nb_steps=t, 
                          max_time=t)

        model.inference('/local/work/enguyen/synthetic/two_weights.pt')
        return model
    elif nb_layers == 3:
        params_threelayer = {'time_step': 0.001,
               'tau_syn': 0.01,
               'tau_mem': 0.001,
               'optimizer': optim.Adam,
               'learning_rate': 0.01,
               'batch_size': 128,
               'nb_hiddens': [10, 10]}
        model = SNN(hyperparams=params_threelayer, 
                          nb_inputs=nb_inputs, 
                          nb_outputs=nb_outputs, 
                          nb_layers=3, 
                          nb_steps=t, 
                          max_time=t)
        model.inference('/local/work/enguyen/synthetic/three_weights.pt')
        return model

"""# Get all the explanations for the quantitative analysis

so that it does not have to be recomputed for each metric
"""

def extract_explanations_for_quantitative_analysis(testset_t, explanation_type, nb_layers, X_data, y_data, filename):
    """
    Helper function to extract the X_spikes, explanations (attribution maps) and the prediction for a model
    :param testset_t: the timestamps to be run and extract explanations for
    :param explanation_type: string defining the explanation type: s, ns, ns2 or ncs
    :param nb_layers: amount of layers of the model
    :param X_data: data in the dictionary times, units form
    :param y_data: labels
    :param filename: string of the filename to save the information under
    """
    testset_explanations = {}
    for t in tqdm(testset_t): 
        # get the relevant part of the dataset, this is done for performance reasons
        start_t = t-1000 if t>=1000 else 0
        X = {'times': X_data['times'][:, np.where((X_data['times']>=start_t) & (X_data['times']<t))[1]]-start_t, 
             'units': X_data['units'][:, np.where((X_data['times']>=start_t) & (X_data['times']<t))[1]]}
        y = y_data[:, start_t:t]

        model = initiate_model(nb_layers, (t-start_t))
        
        #reset synaptic currents and membrane potentials to fit the data duration 
        model.syns=[]
        model.mems=[]
        for l in range(model.nb_layers):
            model.syns.append(torch.zeros((len(y),model.layer_sizes[l+1]), device=device, dtype=dtype))
            model.mems.append(torch.zeros((len(y),model.layer_sizes[l+1]), device=device, dtype=dtype))

        y_pred, log_p_y, layer_recs = model.predict(X, y)
        probs = torch.exp(log_p_y)[0].t()
        data_generator = sparse_data_generator_from_spikes(X, y, len(y), model.nb_steps, model.layer_sizes[0], model.max_time, shuffle=False)
        X_spikes, _ = next(data_generator)

        if explanation_type == 'ncs':
            attribution = ncs_attribution_map_mm(model, X_spikes, layer_recs, probs[-1], t-start_t, tsa_variant='s')
        else: 
            attribution = attribution_map_mm(model, X_spikes, layer_recs, probs[-1], t-start_t, explanation_type)
        prediction = y_pred[0][-1]
        e = attribution[prediction]

        testset_explanations[t] = (e.detach(), prediction)
        save_obj(testset_explanations, '/local/work/enguyen/nocw/'+filename+'_'+explanation_type+'.pkl')
        
        
extract_explanations_for_quantitative_analysis(testset_expl, 'ns2', 1, syn_data['X_test'], syn_data['y_test'], 'expl_one_syn_nocw')
extract_explanations_for_quantitative_analysis(testset_expl, 'ns2', 2, syn_data['X_test'], syn_data['y_test'],  'expl_two_syn_nocw')
extract_explanations_for_quantitative_analysis(testset_expl, 'ns2', 3, syn_data['X_test'], syn_data['y_test'], 'expl_three_syn_nocw')

extract_explanations_for_quantitative_analysis(testset_expl, 's', 1, syn_data['X_test'], syn_data['y_test'], 'expl_one_syn_nocw')
extract_explanations_for_quantitative_analysis(testset_expl, 's', 2, syn_data['X_test'], syn_data['y_test'],  'expl_two_syn_nocw')
extract_explanations_for_quantitative_analysis(testset_expl, 's', 3, syn_data['X_test'], syn_data['y_test'], 'expl_three_syn_nocw')
